# FrameWright Docker Environment Configuration
# Copy this file to .env and customize as needed:
#   cp .env.example .env

# ============================================================
# Directory Configuration
# ============================================================

# Input directory containing videos to process
INPUT_DIR=./input

# Output directory for processed videos
OUTPUT_DIR=./output

# Directory for AI models (downloaded automatically if not present)
MODEL_DIR=./models

# Watch directory for batch processing mode
WATCH_DIR=./watch

# Directory for processed files (moved after successful processing)
PROCESSED_DIR=./processed

# ============================================================
# Device Configuration
# ============================================================

# Processing device: cpu, cuda, or auto
DEVICE=auto

# GPU device selection (for multi-GPU systems)
# Options: "all", "0", "0,1", etc.
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=all

# Number of GPUs to use (for docker-compose.gpu.yml)
# Options: "all", or numeric count: 1, 2, etc.
GPU_COUNT=all

# ============================================================
# Web UI Configuration
# ============================================================

# Port for Gradio web interface
UI_PORT=7860

# ============================================================
# Processing Configuration
# ============================================================

# Default processing preset
# Options: fast, balanced, quality, ultra
PRESET=quality

# Watch mode polling interval (seconds)
WATCH_INTERVAL=60

# ============================================================
# Performance Tuning
# ============================================================

# Enable CUDA memory optimization for large videos
# Set to 1 to enable expandable memory segments
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# Enable synchronous CUDA operations (for debugging)
# Set to 1 to enable, slows down processing
CUDA_LAUNCH_BLOCKING=0

# Enable TensorFloat-32 on Ampere+ GPUs (faster but slightly less precise)
# Set to 1 to enable (recommended for most use cases)
NVIDIA_TF32_OVERRIDE=1

# ============================================================
# Model Configuration
# ============================================================

# Real-ESRGAN model for upscaling
# Options: realesrgan-x4plus, realesrgan-x4plus-anime, realesr-animevideov3
REALESRGAN_MODEL=realesrgan-x4plus

# RIFE model for frame interpolation
# Options: rife-v4, rife-v4.6
RIFE_MODEL=rife-v4

# ============================================================
# Logging Configuration
# ============================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ============================================================
# Resource Limits (optional)
# ============================================================

# Memory limit for containers (e.g., "8g", "16g")
# MEMORY_LIMIT=16g

# CPU limit (number of cores)
# CPU_LIMIT=4

# Shared memory size for PyTorch (required for GPU multi-worker dataloaders)
# SHM_SIZE=8gb
